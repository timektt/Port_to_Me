import React from "react";
import { useNavigate } from "react-router-dom";
import Comments from "../../../components/common/Comments";
import SupportMeButton from "../../../support/SupportMeButton";
import ScrollSpy_Ai_Day6 from "./scrollspy/ScrollSpy_Ai_Day6";
import MiniQuiz_Day6 from "./miniquiz/MiniQuiz_Day6";

const Day6_ActivationFunctions = ({ theme }) => {
  const navigate = useNavigate();

  return (
    <div
      className={`relative min-h-screen ${
        theme === "dark" ? "bg-gray-900 text-white" : "bg-gray-100 text-black"
      }`}
    >
      <main className="max-w-3xl mx-auto p-6 pt-20">
        <h1 className="text-3xl font-bold mb-6">Day 6: Activation Functions</h1>

        <section id="why-not-linear" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4 text-center">‡∏ó‡∏≥‡πÑ‡∏° Linear ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡∏û‡∏≠?</h2>

  <img
    src="/ActivationFunctions1.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />

  <p className="mb-4">
    ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡πÅ‡∏ö‡∏ö Linear ‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏à‡∏∞‡∏¢‡∏±‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡∏ì‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (Linear of Linear = Linear) ‚Üí ‡∏ô‡∏±‡πà‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
  </p>

  <div className="bg-yellow-50 dark:bg-yellow-900 text-black dark:text-yellow-200 p-4 rounded-xl text-sm border-l-4 border-yellow-500 shadow mb-6">
    <strong>Insight:</strong> ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Activation Function ‚Üí Neural Network ‡∏Å‡πá‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡∏ì‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡πÅ‡∏ö‡∏ö‡∏¢‡∏≤‡∏ß ‡πÜ ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏•‡∏±‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ ‚Äú‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‚Äù ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
  </div>

  <p className="mb-4">
    ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏¥‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á <strong>XOR</strong> ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á (linear boundary):
  </p>

  <pre className="bg-gray-800 text-white p-4 text-sm rounded-md overflow-x-auto mb-4"># XOR Problem
# Input: [0,0] ‚Üí 0
#        [0,1] ‚Üí 1
#        [1,0] ‚Üí 1
#        [1,1] ‚Üí 0
# ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÉ‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å output = 1 ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å output = 0 ‡πÑ‡∏î‡πâ
  </pre>

  <p className="mb-4">
    ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‚Äú‡∏á‡∏≠‡πÄ‡∏™‡πâ‡∏ô‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÅ‡∏î‡∏ô‚Äù ‡πÑ‡∏î‡πâ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà Linear Layer ‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô (non-linearity) ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÅ‡∏ó‡∏£‡∏Å‡πÅ‡∏ã‡∏á
  </p>

  <div className="grid sm:grid-cols-2 gap-6 my-8">
    <div>
      <h3 className="text-lg font-semibold mb-2"> Linear-only Model</h3>
      <ul className="list-disc pl-6 text-sm space-y-1">
        <li>‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏á‡∏≠‡πÄ‡∏™‡πâ‡∏ô decision boundary</li>
        <li>‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ pattern ‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô</li>
        <li>‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á XOR, ‡∏†‡∏≤‡∏û‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô, ‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÑ‡∏î‡πâ</li>
      </ul>
    </div>
    <div>
      <h3 className="text-lg font-semibold mb-2"> Linear + Activation</h3>
      <ul className="list-disc pl-6 text-sm space-y-1">
        <li>‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏á‡∏≠ decision boundary ‡πÑ‡∏î‡πâ</li>
        <li>‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à pattern ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô</li>
        <li>‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ ‚Äú‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‚Äù ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡πÅ‡∏ö‡∏ö‡∏â‡∏•‡∏≤‡∏î</li>
      </ul>
    </div>
  </div>

  <p className="mb-4">
    ‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà Activation Function ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Linear Layers ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ Neural Network ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô <strong>Universal Function Approximator</strong> ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏Ñ‡∏∑‡∏≠‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÅ‡∏ó‡∏ö‡∏ó‡∏∏‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏Ñ‡πâ‡∏á‡πÄ‡∏ß‡πâ‡∏≤, ‡∏Ñ‡∏•‡∏∑‡πà‡∏ô, ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
  </p>

  <h3 className="text-lg font-semibold mt-6 mb-2 text-center">‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏°‡∏µ Activation</h3>

  <img
    src="/ActivationFunctions2.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />
  <div className="grid sm:grid-cols-2 gap-6 items-center">
    <div>
      <p className="text-sm mb-2"> ‡πÑ‡∏°‡πà‡∏°‡∏µ Activation (Linear Only):</p>
      <ul className="list-disc pl-6 space-y-1 text-sm">
        <li>‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô</li>
        <li>Decision Boundary ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á</li>
        <li>Performance ‡∏ï‡πà‡∏≥‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô</li>
      </ul>
    </div>
    <div>
      <p className="text-sm mb-2"> ‡∏°‡∏µ Activation (Linear + ReLU):</p>
      <ul className="list-disc pl-6 space-y-1 text-sm">
        <li>‡∏™‡∏£‡πâ‡∏≤‡∏á decision boundary ‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡πâ‡∏á</li>
        <li>‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Feature ‡∏•‡∏∂‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö</li>
        <li>‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô CNN, RNN, Transformer</li>
      </ul>
    </div>
  </div>


  <div className="bg-yellow-100 dark:bg-yellow-200 text-black p-4 rounded-xl text-sm border-l-4 border-yellow-500 shadow mt-6">
    <strong>Insight:</strong><br />
    ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏ö‡∏ö linear ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏•‡∏ô‡∏™‡πå‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‡πÅ‡∏ï‡πà Activation ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏•‡∏ô‡∏™‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡πÑ‡∏î‡πâ‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô ‚Äî ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà Neural Network ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏°‡∏±‡∏ô
  </div>
</section>


<section id="what-is-activation" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4 text-center">Activation Function ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?</h2>

  <img
    src="/ActivationFunctions3.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />

  <p className="mb-4 text-base leading-relaxed">
    Activation Function ‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏ó‡∏£‡∏Å‡πÑ‡∏ß‡πâ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Linear Transformation ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á Neural Network ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á (Non-linearity) ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö ‡∏ã‡∏∂‡πà‡∏á‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ
  </p>

  <p className="mb-4 text-base leading-relaxed">
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ Activation Function ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡πÅ‡∏ö‡∏ö Linear ‡∏à‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏π‡∏Å‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡∏ì‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (Linear of Linear = Linear) ‡∏ô‡∏±‡πà‡∏ô‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏ó‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á (non-linearly separable) ‡∏≠‡∏¢‡πà‡∏≤‡∏á XOR ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏á‡∏á‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
  </p>

  <h3 className="text-xl font-semibold mb-3">‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (XOR Problem)</h3>


  <p className="mb-4">
    ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ XOR ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏¥‡∏Å‡∏ó‡∏µ‡πà Linear Model ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏á‡∏á‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢ ‡∏ã‡∏∂‡πà‡∏á Activation Function ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
  </p>

  <img
    src="/ActivationFunctions4.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />


  <h3 className="text-xl font-semibold mb-3">‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á Activation Function</h3>
  <ul className="list-disc pl-6 space-y-2 mb-6">
    <li><strong>‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô:</strong> ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ</li>
    <li><strong>‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:</strong> ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå (ReLU)</li>
    <li><strong>‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï:</strong> ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ä‡πà‡∏ô -1 ‡∏ñ‡∏∂‡∏á 1 (Tanh)</li>
    <li><strong>‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á:</strong> ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏î‡πâ‡∏ß‡∏¢ Gradient Descent ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏ö‡∏£‡∏∑‡πà‡∏ô</li>
  </ul>

  <h3 className="text-xl font-semibold mb-3">‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Activation Function ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢</h3>
  <div className="overflow-x-auto mb-6">
    <table className="w-full table-auto text-sm border border-yellow-500">
      <thead>
        <tr className="bg-yellow-100 dark:bg-yellow-900 text-left">
          <th className="p-2 border border-yellow-400">‡∏ä‡∏∑‡πà‡∏≠</th>
          <th className="p-2 border border-yellow-400">‡∏ô‡∏¥‡∏¢‡∏≤‡∏°</th>
          <th className="p-2 border border-yellow-400">‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤</th>
          <th className="p-2 border border-yellow-400">‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô</th>
          <th className="p-2 border border-yellow-400">‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td className="p-2 border border-yellow-400 font-semibold">ReLU</td>
          <td className="p-2 border border-yellow-400">f(x) = max(0, x)</td>
          <td className="p-2 border border-yellow-400">[0, ‚àû)</td>
          <td className="p-2 border border-yellow-400">‡∏á‡πà‡∏≤‡∏¢, ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏£‡πá‡∏ß, ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î vanishing gradient</td>
          <td className="p-2 border border-yellow-400">‡πÄ‡∏Å‡∏¥‡∏î dead neuron ‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤ &lt; 0</td>
        </tr>
        <tr>
          <td className="p-2 border border-yellow-400 font-semibold">Sigmoid</td>
          <td className="p-2 border border-yellow-400">f(x) = 1 / (1 + e^(-x))</td>
          <td className="p-2 border border-yellow-400">(0, 1)</td>
          <td className="p-2 border border-yellow-400">‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö binary output, ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢</td>
          <td className="p-2 border border-yellow-400">gradient ‡∏´‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡∏á/‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ</td>
        </tr>
        <tr>
          <td className="p-2 border border-yellow-400 font-semibold">Tanh</td>
          <td className="p-2 border border-yellow-400">f(x) = (e^x - e^(-x)) / (e^x + e^(-x))</td>
          <td className="p-2 border border-yellow-400">[-1, 1]</td>
          <td className="p-2 border border-yellow-400">‡∏°‡∏µ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà 0, gradient ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ sigmoid</td>
          <td className="p-2 border border-yellow-400">‡∏¢‡∏±‡∏á‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤ vanishing gradient ‡πÑ‡∏î‡πâ</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3 className="text-xl font-semibold mb-3">Insight ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</h3>
  <div className="bg-yellow-50 dark:bg-yellow-900 text-black dark:text-yellow-100 p-4 rounded-xl text-sm border-l-4 border-yellow-500 shadow">
    Activation Function ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô "‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ç‡∏ç‡∏≤‡∏ì" ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏°‡∏±‡∏ô ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏™‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
  </div>

</section>


<section id="compare-activations" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4">‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ReLU, Sigmoid, Tanh</h2>

  <p className="mb-6 text-base">
    Activation Function ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á ‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
    ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á ReLU, Sigmoid ‡πÅ‡∏•‡∏∞ Tanh
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
  </p>

  <div className="grid md:grid-cols-3 gap-6">
    <div className="bg-gray-100 dark:bg-gray-800 p-4 rounded-xl shadow border border-yellow-400">
      <h3 className="text-lg font-semibold mb-2">üîπ ReLU (Rectified Linear Unit)</h3>
      <p className="text-sm mb-2">f(x) = max(0, x)</p>
      <ul className="list-disc pl-6 space-y-1 text-sm">
        <li>‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô</li>
        <li>‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å (Deep Neural Networks)</li>
        <li>‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ vanishing gradient ‡πÑ‡∏î‡πâ‡∏î‡∏µ</li>
        <li>‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Dead Neuron ‚Äî ‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô 0</li>
        <li>‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÉ‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å</li>
      </ul>
    </div>

    <div className="bg-gray-100 dark:bg-gray-800 p-4 rounded-xl shadow border border-blue-400">
      <h3 className="text-lg font-semibold mb-2">üîπ Sigmoid</h3>
      <p className="text-sm mb-2">f(x) = 1 / (1 + e^-x)</p>
      <ul className="list-disc pl-6 space-y-1 text-sm">
        <li>‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0 ‡∏ñ‡∏∂‡∏á 1</li>
        <li>‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô classification ‡∏ó‡∏µ‡πà‡∏°‡∏µ 2 classes (binary)</li>
        <li>‡∏°‡∏µ interpretability ‡∏™‡∏π‡∏á (‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢)</li>
        <li>‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ vanishing gradient ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å 0</li>
        <li>‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ä‡πâ‡∏≤‡πÉ‡∏ô‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏•‡∏∂‡∏Å</li>
      </ul>
    </div>

    <div className="bg-gray-100 dark:bg-gray-800 p-4 rounded-xl shadow border border-pink-400">
      <h3 className="text-lg font-semibold mb-2">üîπ Tanh (Hyperbolic Tangent)</h3>
      <p className="text-sm mb-2">f(x) = (e^x - e^-x) / (e^x + e^-x)</p>
      <ul className="list-disc pl-6 space-y-1 text-sm">
        <li>‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á -1 ‡∏ñ‡∏∂‡∏á 1</li>
        <li>‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ sigmoid ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ centered ‡∏ó‡∏µ‡πà 0</li>
        <li>‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö input ‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß</li>
        <li>‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ vanishing gradient ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô sigmoid</li>
        <li>‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• recurrent ‡πÄ‡∏ä‡πà‡∏ô RNN</li>
      </ul>
    </div>
  </div>

  <div className="mt-10">
  <h3 className="text-xl font-semibold mb-3">‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡∏™‡∏£‡∏∏‡∏õ</h3>

  <div className="overflow-x-auto">
    <table className="min-w-[600px] text-sm border-collapse border">
      <thead>
        <tr className="bg-yellow-200 text-black">
          <th className="border px-3 py-2 text-left">Activation</th>
          <th className="border px-3 py-2 text-left">Range</th>
          <th className="border px-3 py-2 text-left">‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö</th>
          <th className="border px-3 py-2 text-left">‡∏Ç‡πâ‡∏≠‡∏î‡∏µ</th>
          <th className="border px-3 py-2 text-left">‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢</th>
        </tr>
      </thead>
      <tbody>
        <tr className="bg-white dark:bg-gray-700">
          <td className="border px-3 py-2">ReLU</td>
          <td className="border px-3 py-2">[0, ‚àû)</td>
          <td className="border px-3 py-2">CNN, DNN</td>
          <td className="border px-3 py-2">‡πÄ‡∏£‡πá‡∏ß, ‡∏•‡∏î gradient ‡∏´‡∏≤‡∏¢</td>
          <td className="border px-3 py-2">Dead Neuron</td>
        </tr>
        <tr className="bg-gray-50 dark:bg-gray-800">
          <td className="border px-3 py-2">Sigmoid</td>
          <td className="border px-3 py-2">[0, 1]</td>
          <td className="border px-3 py-2">Binary Output</td>
          <td className="border px-3 py-2">‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢</td>
          <td className="border px-3 py-2">Vanishing Gradient</td>
        </tr>
        <tr className="bg-white dark:bg-gray-700">
          <td className="border px-3 py-2">Tanh</td>
          <td className="border px-3 py-2">[-1, 1]</td>
          <td className="border px-3 py-2">RNN, NLP</td>
          <td className="border px-3 py-2">Centered ‡∏ó‡∏µ‡πà 0</td>
          <td className="border px-3 py-2">‡∏¢‡∏±‡∏á‡∏°‡∏µ gradient ‡∏´‡∏≤‡∏¢</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


  <div className="bg-yellow-100 dark:bg-yellow-200 text-black p-4 mt-8 rounded-xl text-sm border-l-4 border-yellow-500 shadow">
    <strong>Insight:</strong><br />
    ‡πÑ‡∏°‡πà‡∏°‡∏µ Activation ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå ‚Äî ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á
  </div>
</section>

<section id="modern-activations" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4">Activation Function ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà: Leaky ReLU, GELU, Swish</h2>

  <p className="mb-4">
    ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤ ReLU ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô Activation Function ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ <strong>Dead Neuron</strong> ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏™‡∏°‡∏≠ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ ‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ Activation Function ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏•‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô BERT ‡πÅ‡∏•‡∏∞ GPT
  </p>

  <div className="bg-yellow-100 dark:bg-yellow-800 text-black dark:text-yellow-100 p-4 rounded-xl border-l-4 border-yellow-500 shadow mb-6">
    <strong>Insight:</strong><br />
    Activation Function ‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ Gradient ‡πÑ‡∏´‡∏•‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Gradient ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å ‡πÜ ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
  </div>

  <h3 className="text-xl font-semibold mb-3"> Leaky ReLU</h3>
  <p className="mb-2">
    Leaky ReLU ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å ReLU ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏´‡∏°‡∏î ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡∏°‡∏µ slope ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô 0.01
  </p>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-4">
{`f(x) = x  if x > 0
     = Œ±x if x <= 0  (‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ Œ± = 0.01)`}
  </pre>
  <ul className="list-disc pl-6 space-y-2 mb-4">
    <li>‡∏•‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏Å‡∏¥‡∏î Dead Neuron</li>
    <li>‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ReLU</li>
    <li>‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ä‡πâ‡πÉ‡∏ô GANs ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏û</li>
  </ul>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-6">
{`# PyTorch
import torch.nn as nn

layer = nn.Sequential(
  nn.Linear(64, 32),
  nn.LeakyReLU(negative_slope=0.01)
)`}
  </pre>

  <h3 className="text-xl font-semibold mb-3"> GELU (Gaussian Error Linear Unit)</h3>
  <p className="mb-2">
    GELU ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô BERT ‡πÅ‡∏•‡∏∞ Transformer-based models ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡∏ì x ‡∏î‡πâ‡∏ß‡∏¢ sigmoid-like function ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏° <strong>smooth</strong> ‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ReLU ‡∏´‡∏£‡∏∑‡∏≠ Tanh
  </p>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-4">
{`f(x) = 0.5 * x * (1 + tanh(\u221a(2/\u03c0)*(x + 0.044715x^3)))`}
  </pre>
  <ul className="list-disc pl-6 space-y-2 mb-4">
    <li>‡πÉ‡∏´‡πâ gradient ‡∏ó‡∏µ‡πà‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏• (smooth)</li>
    <li>‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ dead zone ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ReLU</li>
    <li>‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏•‡∏∞ sequence model</li>
  </ul>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-6">
{`# PyTorch
import torch.nn as nn
import torch.nn.functional as F

class MyLayer(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(64, 64)

    def forward(self, x):
        return F.gelu(self.linear(x))`}
  </pre>

  <h3 className="text-xl font-semibold mb-3">Swish</h3>
  <p className="mb-2">
    Swish ‡∏ñ‡∏π‡∏Å‡πÄ‡∏™‡∏ô‡∏≠‡πÇ‡∏î‡∏¢ Google ‡πÄ‡∏õ‡πá‡∏ô Activation Function ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô x ‡∏Ñ‡∏π‡∏ì‡∏Å‡∏±‡∏ö sigmoid(x) ‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡∏ö‡πÅ‡∏•‡∏∞‡∏°‡∏µ gradient ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏•
  </p>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-4">
{`f(x) = x * sigmoid(x)`}
  </pre>
  <ul className="list-disc pl-6 space-y-2 mb-4">
    <li>‡πÉ‡∏´‡πâ gradient ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏•‡∏î‡∏µ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ä‡πà‡∏ß‡∏á</li>
    <li>‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏î‡πâ (‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å ReLU)</li>
    <li>‡πÉ‡∏ä‡πâ‡πÉ‡∏ô EfficientNet ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ balance ‡∏î‡∏µ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á speed ‡πÅ‡∏•‡∏∞ accuracy</li>
  </ul>
  <pre className="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mb-6">
{`# TensorFlow
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.activations import swish

x = Dense(64)(input_tensor)
x = Activation(swish)(x)`}
  </pre>

  <h3 className="text-xl font-semibold mb-4"> ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ReLU vs LeakyReLU vs GELU vs Swish</h3>
  <div className="overflow-x-auto">
    <table className="min-w-full text-sm text-left border border-gray-300 dark:border-gray-600">
      <thead>
        <tr className="bg-gray-200 dark:bg-gray-700">
          <th className="p-2 border">Function</th>
          <th className="p-2 border">‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏î‡πà‡∏ô</th>
          <th className="p-2 border">‡∏Ç‡πâ‡∏≠‡∏î‡∏µ</th>
          <th className="p-2 border">‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td className="p-2 border">ReLU</td>
          <td className="p-2 border">‡∏ï‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÄ‡∏õ‡πá‡∏ô 0</td>
          <td className="p-2 border">‡πÄ‡∏£‡πá‡∏ß, ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏á‡πà‡∏≤‡∏¢</td>
          <td className="p-2 border">Dead Neuron</td>
        </tr>
        <tr>
          <td className="p-2 border">Leaky ReLU</td>
          <td className="p-2 border">‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢</td>
          <td className="p-2 border">‡∏•‡∏î Dead Neuron</td>
          <td className="p-2 border">‡∏°‡∏µ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î (Œ±)</td>
        </tr>
        <tr>
          <td className="p-2 border">GELU</td>
          <td className="p-2 border">smooth non-linearity</td>
          <td className="p-2 border">‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏î‡∏µ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP</td>
          <td className="p-2 border">‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô</td>
        </tr>
        <tr>
          <td className="p-2 border">Swish</td>
          <td className="p-2 border">x * sigmoid(x)</td>
          <td className="p-2 border">‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å & EfficientNet</td>
          <td className="p-2 border">‡∏ä‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ReLU</td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<section id="activation-gradient-flow" className="mb-20 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4 text-center">
    ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á Activation Function ‡∏ï‡πà‡∏≠ Gradient Flow
  </h2>
  <img
    src="/ActivationFunctions5.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />

  <p className="mb-4 text-base">
    ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Neural Network ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏•‡∏∂‡∏Å‡∏°‡∏≤‡∏Å (Deep Neural Network) ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤ Gradient ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏£‡∏ì‡∏µ ‡∏Ñ‡πà‡∏≤ Gradient ‡∏≠‡∏≤‡∏à <strong>‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Vanishing Gradient)</strong> ‡∏´‡∏£‡∏∑‡∏≠ <strong>‡∏£‡∏∞‡πÄ‡∏ö‡∏¥‡∏î (Exploding Gradient)</strong> ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á Activation Function ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ
  </p>
  <h3 className="text-xl font-semibold mt-6 mb-2"> ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Vanishing Gradient ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?</h3>
  <p className="mb-4">
    ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤ Gradient ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å‡πÉ‡∏Å‡∏•‡πâ‡∏®‡∏π‡∏ô‡∏¢‡πå ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤ Activation Function ‡∏°‡∏µ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà slope ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ô‡∏∏‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ 0 ‚Üí ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• <strong>‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÑ‡∏î‡πâ</strong> ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏•‡∏¢
  </p>

  <h3 className="text-xl font-semibold mb-2"> ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Exploding Gradient ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?</h3>
  <p className="mb-4">
    ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏´‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ Gradient ‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô ‚Üí ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ weight ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á ‡∏à‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ ‡∏´‡∏£‡∏∑‡∏≠ loss ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô NaN ‡πÑ‡∏î‡πâ
  </p>

  <h3 className="text-xl font-semibold mt-6 mb-3"> ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á Activation Function ‡∏ï‡πà‡∏≠ Gradient</h3>
  <table className="table-auto w-full text-sm text-left border mb-6">
    <thead>
      <tr className="bg-yellow-200 dark:bg-yellow-900">
        <th className="border px-3 py-2">Activation</th>
        <th className="border px-3 py-2">‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ Gradient</th>
        <th className="border px-3 py-2">‡∏õ‡∏±‡∏ç‡∏´‡∏≤</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td className="border px-3 py-2">Sigmoid</td>
        <td className="border px-3 py-2">Gradient ‡πÉ‡∏Å‡∏•‡πâ 0 ‡πÄ‡∏°‡∏∑‡πà‡∏≠ x ‚Üí ¬±‚àû</td>
        <td className="border px-3 py-2">Vanishing Gradient</td>
      </tr>
      <tr>
        <td className="border px-3 py-2">Tanh</td>
        <td className="border px-3 py-2">‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Sigmoid ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô</td>
        <td className="border px-3 py-2">Vanishing (‡πÅ‡∏ï‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ Sigmoid)</td>
      </tr>
      <tr>
        <td className="border px-3 py-2">ReLU</td>
        <td className="border px-3 py-2">Gradient = 1 ‡πÄ‡∏°‡∏∑‡πà‡∏≠ x &gt; 0</td>
        <td className="border px-3 py-2">Dead Neuron (x &lt; 0)</td>
      </tr>
      <tr>
        <td className="border px-3 py-2">Leaky ReLU</td>
        <td className="border px-3 py-2">Gradient ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î = 0.01</td>
        <td className="border px-3 py-2">‡∏•‡∏î Dead Neuron</td>
      </tr>
      <tr>
        <td className="border px-3 py-2">GELU</td>
        <td className="border px-3 py-2">Smooth ‡πÅ‡∏•‡∏∞‡∏°‡∏µ slope ‡∏ó‡∏µ‡πà‡∏î‡∏µ</td>
        <td className="border px-3 py-2">‡∏£‡∏±‡∏Å‡∏©‡∏≤ Gradient ‡πÑ‡∏î‡πâ‡∏î‡∏µ</td>
      </tr>
    </tbody>
  </table>


  <h3 className="text-xl font-semibold mt-6 mb-3"> ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Vanishing/Exploding</h3>
  <ul className="list-disc pl-6 space-y-2">
    <li>‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Activation ‡∏ó‡∏µ‡πà‡∏°‡∏µ slope ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ReLU, Leaky ReLU, GELU</li>
    <li>‡πÉ‡∏ä‡πâ Weight Initialization ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÄ‡∏ä‡πà‡∏ô Xavier ‡∏´‡∏£‡∏∑‡∏≠ He init)</li>
    <li>‡πÉ‡∏ä‡πâ Batch Normalization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô</li>
    <li>‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Learning Rate ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏≠‡πÄ‡∏´‡∏°‡∏≤‡∏∞</li>
  </ul>

  <div className="bg-yellow-100 dark:bg-yellow-200 text-black p-4 mt-8 rounded-xl text-sm border-l-4 border-yellow-500 shadow">
    <strong>Insight:</strong><br />
    ‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á Gradient ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏£‡∏∞‡πÅ‡∏™‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏´‡∏≤‡∏Å Activation Function ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡πÑ‡∏´‡∏•‡πÑ‡∏°‡πà‡∏ó‡∏±‡πà‡∏ß‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ ‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ä‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
  </div>
</section>



<section id="activation-in-code" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4">‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Activation ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á</h2>

  <p className="mb-4 text-base">
    ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á Activation Function ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏°‡∏µ‡∏ú‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ
    ‡πÇ‡∏î‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô PyTorch ‡πÅ‡∏•‡∏∞ TensorFlow (Keras)
  </p>

  <h3 className="text-xl font-semibold mt-6 mb-2"> PyTorch</h3>
  <p className="mb-2">
    ‡πÉ‡∏ô PyTorch ‡∏à‡∏∞‡πÉ‡∏ä‡πâ <code>nn.Sequential</code> ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏ß‡∏≤‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà Activation ‡πÅ‡∏ö‡∏ö‡πÅ‡∏¢‡∏Å‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ReLU, Sigmoid ‡∏´‡∏£‡∏∑‡∏≠ Tanh
  </p>

  <pre className="bg-gray-800 text-white p-4 rounded-md text-sm overflow-x-auto mb-4">
{`import torch
import torch.nn as nn

model = nn.Sequential(
  nn.Linear(4, 8),   # Linear layer 1
  nn.ReLU(),         # Activation: ReLU
  nn.Linear(8, 4),   # Linear layer 2
  nn.Tanh(),         # Activation: Tanh
  nn.Linear(4, 1),   # Linear layer 3
  nn.Sigmoid()       # Activation: Sigmoid (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö output ‡∏£‡∏∞‡∏î‡∏±‡∏ö 0-1)
)

x = torch.randn(1, 4)
output = model(x)
print(output)`}
  </pre>

  <p className="mb-4">
    ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô activation ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå
    ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á activation ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô LeakyReLU ‡∏´‡∏£‡∏∑‡∏≠ Custom Function
  </p>

  <h3 className="text-xl font-semibold mt-6 mb-2"> TensorFlow (Keras)</h3>
  <p className="mb-2">
    ‡πÉ‡∏ô Keras ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡πÅ‡∏¢‡∏Å‡∏ä‡∏±‡πâ‡∏ô <code>Activation()</code> ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡∏ö‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠ activation ‡∏ï‡∏£‡∏á‡πÉ‡∏ô <code>Dense(..., activation="relu")</code> ‡∏Å‡πá‡πÑ‡∏î‡πâ
  </p>

  <pre className="bg-gray-800 text-white p-4 rounded-md text-sm overflow-x-auto mb-4">
{`from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Activation

# ‡πÅ‡∏ö‡∏ö‡πÅ‡∏¢‡∏Å‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå Activation ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
model = Sequential([
  Dense(8, input_shape=(4,)),
  Activation('relu'),
  Dense(4),
  Activation('tanh'),
  Dense(1),
  Activation('sigmoid')
])`}
  </pre>

  <p className="mb-4">‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡πÉ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:</p>

  <pre className="bg-gray-800 text-white p-4 rounded-md text-sm overflow-x-auto mb-4">
{`# ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏° activation ‡πÉ‡∏ô Dense
model = Sequential([
  Dense(8, activation='relu', input_shape=(4,)),
  Dense(4, activation='tanh'),
  Dense(1, activation='sigmoid')
])`}
  </pre>

  <p className="mb-4">
    Keras ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÅ‡∏•‡∏∞‡∏°‡∏µ activation function ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô Softmax, Swish, GELU
  </p>

  <div className="bg-yellow-100 dark:bg-yellow-200 text-black p-4 rounded-xl text-sm border-l-4 border-yellow-500 shadow mt-6">
    <strong>Insight:</strong><br />
    ‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà Activation Function ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏â‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ activation ‚Üí ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏Å‡∏µ‡πà‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå ‡∏Å‡πá‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
  </div>

  <p className="mt-6">
     ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏î‡∏π <strong>Insight ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö</strong> ‡∏ß‡πà‡∏≤ Activation Function ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‚Äú‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‚Äù ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î
  </p>
</section>




{/* ‡∏ß‡∏≤‡∏á Section ‡∏ô‡∏µ‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô Mini Quiz */}
<section id="activation-selection" className="mb-20 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-6 text-center">‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Activation Function ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô</h2>
  <img
    src="/ActivationFunctions6.png"
    alt="Linear Transformation"
    className="w-full max-w-md mx-auto rounded-xl shadow-lg border border-yellow-400 my-8"
  />


  <p className="mb-4 text-base leading-relaxed">
    ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Activation Function ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏π‡∏ï‡∏£‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÅ‡∏ï‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (task) ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô  
    ‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏¥‡∏î ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏ä‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô Dead Neuron ‡∏´‡∏£‡∏∑‡∏≠ Vanishing Gradient)
  </p>

  <p className="mb-4">
    ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Activation Function ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:
  </p>

  <div className="overflow-x-auto mb-6">
    <table className="w-full text-left border border-gray-400 text-sm rounded overflow-hidden">
      <thead className="bg-gray-200 dark:bg-gray-700 text-black dark:text-white">
        <tr>
          <th className="p-3 border border-gray-400">‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô</th>
          <th className="p-3 border border-gray-400">Activation ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</th>
          <th className="p-3 border border-gray-400">‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•</th>
        </tr>
      </thead>
      <tbody className="bg-white dark:bg-gray-800 text-black dark:text-white">
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">Classification (Binary)</td>
          <td className="p-3 border border-gray-400">Sigmoid</td>
          <td className="p-3 border border-gray-400">‡πÅ‡∏õ‡∏•‡∏á output ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0‚Äì1 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">Classification (Multiclass)</td>
          <td className="p-3 border border-gray-400">Softmax</td>
          <td className="p-3 border border-gray-400">‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏ß‡∏° = 1 ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">Regression</td>
          <td className="p-3 border border-gray-400">Linear / None</td>
          <td className="p-3 border border-gray-400">‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ö‡∏µ‡∏ö‡∏Ñ‡πà‡∏≤ output ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏≠‡∏≤‡∏à‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏à‡∏≥‡∏Å‡∏±‡∏î</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">NLP (Transformer, BERT, GPT)</td>
          <td className="p-3 border border-gray-400">GELU / Swish</td>
          <td className="p-3 border border-gray-400">‡πÉ‡∏´‡πâ gradient ‡∏ó‡∏µ‡πà smooth ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">Vision (CNN, ImageNet)</td>
          <td className="p-3 border border-gray-400">ReLU / Leaky ReLU</td>
          <td className="p-3 border border-gray-400">‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Dead Neuron ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">GAN Generator</td>
          <td className="p-3 border border-gray-400">ReLU / Tanh</td>
          <td className="p-3 border border-gray-400">ReLU ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sparse ‡∏™‡πà‡∏ß‡∏ô Tanh ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£ normalize output</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">GAN Discriminator</td>
          <td className="p-3 border border-gray-400">Leaky ReLU</td>
          <td className="p-3 border border-gray-400">‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ gradient ‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢‡∏Ç‡∏ì‡∏∞ training ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢</td>
        </tr>
        <tr>
          <td className="p-3 border border-gray-400 font-semibold">Autoencoder</td>
          <td className="p-3 border border-gray-400">Tanh / ReLU</td>
          <td className="p-3 border border-gray-400">Tanh ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß ‡∏™‡πà‡∏ß‡∏ô ReLU ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3 className="text-lg font-semibold mt-8 mb-2">‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°</h3>
  <ul className="list-disc pl-6 space-y-2 mb-4 text-base">
    <li>‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Activation ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏∏‡∏Å‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå ‚Äî ‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ ReLU ‡∏ä‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ Swish ‡πÉ‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡∏•‡∏∂‡∏Å</li>
    <li>‡∏ö‡∏≤‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ GELU ‡πÅ‡∏ó‡∏ô ReLU ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢</li>
    <li>‡∏•‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢ Activation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö task ‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏¢‡∏∂‡∏î‡∏ï‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÅ‡∏ö‡∏ö‡∏´‡∏ô‡∏∂‡πà‡∏á</li>
  </ul>

  <div className="bg-yellow-100 dark:bg-yellow-200 text-black p-4 rounded-xl text-sm border-l-4 border-yellow-500 shadow mt-6">
    <strong>Insight:</strong><br />
    Activation Function ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á ‚Äú‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‚Äù ‡πÅ‡∏ï‡πà‡∏Ñ‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏Å‡∏≥‡∏´‡∏ô‡∏î "‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"  
    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞ = ‡πÄ‡∏õ‡∏¥‡∏î‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà
  </div>
</section>

<section id="insight-activation" className="mb-20 scroll-mt-32">
  <div className="bg-yellow-50 dark:bg-yellow-900 text-black dark:text-yellow-100 p-6 rounded-xl border-l-4 border-yellow-500 shadow-xl">
    <h2 className="text-xl font-semibold mb-4">Insight: Activation = "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï" ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•</h2>

    <p className="mb-4">
      ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ Activation Function ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏π‡∏ì‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏ã‡πâ‡∏≥ ‡πÜ ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    </p>

    <p className="mb-4">
      Activation Function ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö "‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å" ‡πÉ‡∏ô‡∏™‡∏°‡∏≠‡∏á ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏≠‡∏¢‡∏π‡πà ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏î‡πâ
    </p>

    <p className="mb-4">
      ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ Activation ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏´‡∏∏‡πà‡∏ô‡∏¢‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏™‡πà Activation ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏•‡∏∂‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    </p>

    <p className="mb-4">
      ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á Linear Layer 10 ‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô Matrix ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ Linear ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á ‡∏ô‡∏±‡πà‡∏ô‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡πÄ‡∏•‡∏¢‡∏´‡∏≤‡∏Å‡∏Ç‡∏≤‡∏î Non-linearity ‡∏ã‡∏∂‡πà‡∏á Activation ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å‡∏°‡∏µ‡∏û‡∏•‡∏±‡∏á
    </p>

    <p className="mb-4">
      Activation ‡∏¢‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£ "‡∏ö‡∏µ‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏¢‡∏≤‡∏¢" ‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ä‡πà‡∏ô ReLU ‡∏à‡∏∞‡∏ï‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡πâ‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏´‡∏£‡∏∑‡∏≠ Sigmoid ‡∏à‡∏∞‡∏ö‡∏µ‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0 ‡∏ñ‡∏∂‡∏á 1 ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Classification
    </p>

    <p className="mb-4">
      ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏µ Activation Function ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ ‚Üí ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û ‡πÉ‡∏ä‡πâ ReLU ‡∏°‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Saturation, ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ probability ‚Üí Sigmoid ‡∏à‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏ß‡πà‡∏≤
    </p>

    <p className="mb-4">
      ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ Activation ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ Activation ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏á ‡πÅ‡∏¢‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ö‡πà‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ
    </p>

    <p className="mb-4">
      ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ Activation ‡∏¢‡∏±‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î Gradient ‚Üí ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ Slope ‡πÅ‡∏õ‡∏£‡∏ú‡∏±‡∏ô‡∏ï‡πà‡∏≠ input ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÑ‡∏´‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö (Backpropagation) ‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    </p>

    <p className="mb-4">
      ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÇ‡∏•‡∏Å‡∏Ç‡∏≠‡∏á Deep Learning ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ Activation ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô Leaky ReLU, GELU, Swish ‡∏ã‡∏∂‡πà‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏ä‡πà‡∏ô Dead Neuron ‡∏´‡∏£‡∏∑‡∏≠ Gradient Vanishing ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏∂‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    </p>

    <p className="mb-4 italic text-gray-700 dark:text-gray-400">
      "Activation ‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏µ‡∏û‡∏à‡∏£‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏• ‚Äî ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏°‡∏±‡∏ô AI ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏à‡∏¥‡∏ï‡πÉ‡∏à"
    </p>
  </div>
</section>


<section id="read-more" className="mb-16 scroll-mt-32">
  <h2 className="text-2xl font-semibold mb-4">‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°</h2>

  <p className="mb-4">
    ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Activation Functions ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô BERT, GPT ‡∏´‡∏£‡∏∑‡∏≠ CNN ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
  </p>

  <ul className="list-disc pl-6 space-y-3 text-base">
    <li>
       <a href="https://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">CS231n - Activation Functions</a><br />
      ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏¥‡∏Å‡∏à‡∏≤‡∏Å Stanford University ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á activation ‡πÑ‡∏î‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
    </li>

    <li>
       <a href="https://arxiv.org/abs/1606.08415" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">Swish: A Self-Gated Activation Function</a><br />
      ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏à‡∏≤‡∏Å Google ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠ Swish ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ReLU ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    </li>

    <li>
       <a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">HuggingFace Transformers</a><br />
      ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡πÅ‡∏•‡∏∞ Activation Function ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô BERT, GPT ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô
    </li>

    <li>
       <a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">PyTorch Activation Docs</a><br />
      ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PyTorch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Activation Layers ‡πÄ‡∏ä‡πà‡∏ô ReLU, GELU, Tanh
    </li>

    <li>
       <a href="https://keras.io/api/layers/activations/" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">Keras Activation Functions</a><br />
      ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á TensorFlow/Keras ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° activation functions ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    </li>
  </ul>

</section>


        <section id="quiz" className="mb-16 scroll-mt-32">
          <MiniQuiz_Day6 theme={theme} />
        </section>

        <div className="flex justify-between items-center max-w-5xl mx-auto px-4 mt-4">
          <div className="flex items-center">
            <span className="text-lg font-bold">Tags:</span>
            <button
              onClick={() => navigate("/tags/ai")}
              className="ml-2 px-3 py-1 border border-gray-500 rounded-lg text-green-700 cursor-pointer hover:bg-gray-700 transition"
            >
              ai
            </button>
          </div>
        </div>

        <Comments theme={theme} />
      </main>

      <div className="hidden lg:block fixed right-6 top-[185px] z-50">
        <ScrollSpy_Ai_Day6 />
      </div>

      <SupportMeButton />
    </div>
  );
};

export default Day6_ActivationFunctions;
